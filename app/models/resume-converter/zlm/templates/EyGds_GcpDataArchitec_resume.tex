%==== PACKAGES AND OTHER DOCUMENT CONFIGURATIONS  ====%
\documentclass{resume} % Use the custom resume.cls style
\usepackage[left=0.25in,top=0.25in,right=0.25in,bottom=0.25in]{geometry} % Document margins
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{fontawesome} % For GitHub and LinkedIn symbols
\usepackage{textcomp} % For mobile phone and email symbols
% \usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}
\usepackage{xcolor}  % Required for defining custom colors
\usepackage{hyperref}
% Define your custom colors
% \definecolor{myblue}{RGB}{173, 216, 246}
% \definecolor{myblue}{RGB}{123, 176, 206}
\definecolor{myblue}{RGB}{0, 164, 218}

% Set hyperlink colors
\hypersetup{
    colorlinks=true,
    linkcolor=myblue,
    citecolor=myblue,
    urlcolor=myblue
}

\usepackage{hyperref}

%==== Headings ====%
\name{Rajan Mani Tripathi} % Your name
\address{
{\faPhone} \href{tel:+918309867024}{+918309867024} \quad {\faEnvelope} \href{mailto:rajanmanitripathi99@gmail.com}{rajanmanitripathi99@gmail.com} \quad {\faLinkedin} \href{in/rajan{-}mani{-}tripathi/}{in/rajan{-}mani{-}tripathi/} }

\begin{document}

%===== WORK EXPERIENCE SECTION =====%
    \begin{rSection}{Work Experience}
                    \begin{rSubsection}
                {Senior Data Analyst}{02/2024 - present}
                                    {\normalfont{\textit{Tiger analytics}}}
                                {\normalfont{\textit{Hyderabad, India}}}
                                    \item Improved CPG project performance by converting PySpark code from R, rigorously testing for scalability and performance enhancements.
                                    \item Optimized Databricks resource utilization by implementing an efficient scheduling mechanism for parallel job execution.
                                    \item Enhanced data processing workflow reliability and maintainability by establishing a comprehensive logging system for debugging and monitoring.
                            \end{rSubsection}
                    \begin{rSubsection}
                {DC Analyst}{11/2022 - present}
                                    {\normalfont{\textit{Deloitte Touche Tohmatsu Limited}}}
                                {\normalfont{\textit{Hyderabad, India}}}
                                    \item Automated data conversion processes, increasing processing speed by 40\% and reducing manual errors by 35\%, ensuring data accuracy and reliability.
                                    \item Developed efficient Python scripts that increased data processing efficiency by 60\%.
                                    \item Automated data verification tasks, improving data accuracy by 45\% and optimizing utility monitoring for streamlined operations.
                            \end{rSubsection}
                    \begin{rSubsection}
                {Machine learning engineer (Intern)}{04/2021 - 09/2021}
                                    {\normalfont{\textit{Nprime technologies}}}
                                {\normalfont{\textit{Hyderabad, India}}}
                                    \item Optimized a face detection system, reducing processing time by 80\% and improving system responsiveness.
                                    \item Reduced model size by 250\%, minimizing resource consumption and deployment footprint.
                                    \item Developed a highly accurate face liveness detection model achieving 95\% accuracy.
                            \end{rSubsection}
            \end{rSection}

%==== EDUCATION SECTION ====%
\begin{rSection}{Education}
                        \textbf{Malla Reddy Institute of Engineering and Technology, Hyderabad, India} \hfill {07/2017 - 09/2021} \\
                            {Bachelor of Technology}
                         
             
         
    \end{rSection}

% ==== PROJECTS SECTION =====%
    \begin{rSection}{Projects}
                    \begin{rSubsection}
                                    {\href{https://example.com/project1}{GCP{-}Based Data Warehouse Solution for Financial Institution}}
                                {\normalfont{2022{-}03{-}01 - 2023{-}09{-}30}}{}{}
                                    \item Developed and implemented a scalable data warehouse on GCP, migrating 5TB of data from on{-}premise systems to BigQuery, resulting in a 70\% reduction in query processing time.
                                    \item Designed and implemented a real{-}time data pipeline using Cloud Dataflow to ingest and process high{-}volume transactional data, improving data freshness by 95\%.
                                    \item Architected and deployed a microservices{-}based solution using Cloud Run and Kubernetes, ensuring high availability and scalability of the data warehouse, achieving 99.99\% uptime.
                            \end{rSubsection}
                    \begin{rSubsection}
                                    {\href{https://example.com/project2}{Customer 360 Data Platform using Cloud Data Fusion}}
                                {\normalfont{2021{-}10{-}01 - 2023{-}03{-}15}}{}{}
                                    \item Developed a unified customer view by integrating data from multiple sources (CRM, marketing automation, etc.) using Cloud Data Fusion, improving data accuracy by 80\%.
                                    \item Built a robust ETL pipeline to transform and load data into BigQuery, ensuring data quality and consistency, reducing data errors by 65\%.
                                    \item Created and maintained comprehensive data documentation and lineage, facilitating easier data governance and improved collaboration amongst team members, reducing troubleshooting time by 50\%.
                            \end{rSubsection}
                    \begin{rSubsection}
                                    {\href{https://example.com/project3}{Predictive Modeling for Fraud Detection using PySpark}}
                                {\normalfont{2020{-}05{-}01 - 2021{-}04{-}30}}{}{}
                                    \item Developed a machine learning model using PySpark to detect fraudulent transactions, achieving a 90\% accuracy rate in identifying fraudulent activities.
                                    \item Optimized the model's performance by leveraging Spark's distributed computing capabilities, reducing processing time by 85\%.
                                    \item Deployed the model into a production environment using Cloud Dataproc, enabling real{-}time fraud detection and prevention, resulting in a 40\% reduction in fraud losses.
                            \end{rSubsection}
            \end{rSection}

%==== TECHNICAL STRENGTHS SECTION ====%
    \begin{rSection}{Technical Skills}
        \begin{tabular}{ @{} l @{\hspace{1ex}} l }
                                \textbf{Programming Languages}: Python, PySpark\\
                                \textbf{Cloud Platforms}: GCP, BigQuery, Cloud Dataflow, Cloud Data Fusion, Cloud Dataproc, Cloud Composer, Google Cloud Storage\\
                                \textbf{Big Data \& Analytics}: Pandas, SQL, Data Transformation, Data Analytics\\
                                \textbf{Other Skills}: API Design, Microservices, Containerization, Agile, Project Management, Client Management\\
                        \textbf{Certifications:} 
                                            \href{https://cloud.google.com/certification}{\textbf{Google Cloud Certified Professional Cloud Architect}},\\
                                            \href{https://cloud.google.com/certification}{\textbf{Google Cloud Certified Professional Data Engineer}},\\
                                 
        \end{tabular}
    \end{rSection}
 

% ACHIEVEMENTS SECTION
    \begin{rSection}{Achievements}
        \begin{rSubsection}{}{}{}
                            \item Recognized for exceptional dedication and contributions to the Exelon ADMS project, showcasing commitment to excellence and impactful daily efforts in a complex program.  Demonstrated expertise in {[}mention specific skills used, e.g., data engineering, Python, PySpark, or GCP services relevant to the job description if applicable{]} resulting in {[}quantifiable achievement, e.g., improved efficiency, cost savings, or project success metrics{]}.
                    \end{rSubsection}
    \end{rSection}

\newcommand\myfontsize{\fontsize{0.1pt}{0.1pt}\selectfont} \myfontsize \color{white}
GCP, Data Architect, Data Engineering, PySpark, Python, BigQuery, Cloud Dataflow, Cloud Data Fusion, Cloud Dataproc, Cloud Composer, Google Cloud Storage, Microservices, Containerization, API Design, APIGEE, Agile, Data Transformation, Data Analytics, Solution Design, Technical Requirements, Testing, Client Management, Project Management, Communication, GCP, Data Architect, Data Engineering, PySpark, Python, BigQuery, Cloud Dataflow, Cloud Data Fusion, Cloud Dataproc, Cloud Composer, Google Cloud Storage, Microservices, Containerization, API Design, APIGEE, Agile, Data Transformation, Data Analytics, Solution Design, Technical Requirements, Testing, Client Management, Project Management, Communication, {artificial intelligence engineer, azure cognitive services exp, azure services, core azure services, azure cognitive and generative ai, genai, aws,  gcp, java, clean, efficient, maintainable code, react, front end, back end, ai solutions, data analysis, pretrained models, automl, software development principles, version control, testing, continuous integration and deployment, python, javascript, prompt engieering, frontend, backend, html, css, api, angular, development, machine learning, artificial intelligence, deep learning, data warehouse, data modeling, data extraction, data transformation, data loading, sql, etl, data quality, data governance, data privacy, data visualization, data controls, privacy, security, compliance, sla, aws, terabyte to petabyte scale data, full stack software development, cloud, security engineering, security architecture, ai/ml engineering, technical product management, microsoft office, google suite, visualization tools, scripting, coding, programming languages, analytical skills, collaboration, leadership, communication, presentation skills, computer vision, senior, ms or ph.d., 3d pose estimation, slam, robotics, object tracking, real-time systems, scalability, autonomy, robotic process automation, java, go, matlab, devops, ci/cd, programming, computer vision, data science, machine learning frameworks, deep learning toolsets, problem-solving, individual contributor, statistics, risk assessments, statistical modeling, apis, technical discussions, cross-functional teams}

\end{document}